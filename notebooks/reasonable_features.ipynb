{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m5/9j_7j_8j5m154hyxw8j2346h0000gn/T/ipykernel_44578/2437715761.py:11: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=False)\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from xtx.modeling.time_folds import TimeFolds\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from xtx.modeling.evaluation import ridge_eval\n",
    "from xtx.modeling.runners import CrossValRunner\n",
    "from xtx.features.feature_extractor import FeatureExtractor \n",
    "\n",
    "N_SCALING = 2500000\n",
    "\n",
    "def shrink_dtype(df: pd.DataFrame):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == np.float64:\n",
    "            df[col] = df[col].astype(np.float32)\n",
    "\n",
    "MODEL_CONFIGS = {\n",
    "    'default_ridge': {\n",
    "        'model_module': 'sklearn.linear_model',\n",
    "        'model_cls': 'Ridge',\n",
    "        'model_params': {'alpha': 100}\n",
    "    },\n",
    "    'default_lasso': {\n",
    "        'model_module': 'sklearn.linear_model',\n",
    "        'model_cls': 'Lasso',\n",
    "        'model_params': {'alpha': 0.01}\n",
    "    },\n",
    "    'default_lgbm': {\n",
    "        'model_module': 'lightgbm',\n",
    "        'model_cls': 'LGBMRegressor',\n",
    "        'model_params': {\n",
    "            'n_jobs': -1, \n",
    "            'num_leaves': 13, \n",
    "            'learning_rate': 0.01,\n",
    "            'n_estimators': 500, \n",
    "            'reg_lambda': 1, \n",
    "            'colsample_bytree': 0.7, \n",
    "            'subsample': 0.05\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_pickle('data/data.pkl').fillna(0)\n",
    "# target_col = 'y'\n",
    "# target = data[target_col]\n",
    "# # data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>askRate0</th>\n",
       "      <th>askRate1</th>\n",
       "      <th>askRate2</th>\n",
       "      <th>askRate3</th>\n",
       "      <th>askRate4</th>\n",
       "      <th>askRate5</th>\n",
       "      <th>askRate6</th>\n",
       "      <th>askRate7</th>\n",
       "      <th>askRate8</th>\n",
       "      <th>askRate9</th>\n",
       "      <th>askRate10</th>\n",
       "      <th>askRate11</th>\n",
       "      <th>askRate12</th>\n",
       "      <th>askRate13</th>\n",
       "      <th>askRate14</th>\n",
       "      <th>askSize0</th>\n",
       "      <th>askSize1</th>\n",
       "      <th>askSize2</th>\n",
       "      <th>askSize3</th>\n",
       "      <th>askSize4</th>\n",
       "      <th>askSize5</th>\n",
       "      <th>askSize6</th>\n",
       "      <th>askSize7</th>\n",
       "      <th>askSize8</th>\n",
       "      <th>askSize9</th>\n",
       "      <th>askSize10</th>\n",
       "      <th>askSize11</th>\n",
       "      <th>askSize12</th>\n",
       "      <th>askSize13</th>\n",
       "      <th>askSize14</th>\n",
       "      <th>bidRate0</th>\n",
       "      <th>bidRate1</th>\n",
       "      <th>bidRate2</th>\n",
       "      <th>bidRate3</th>\n",
       "      <th>bidRate4</th>\n",
       "      <th>bidRate5</th>\n",
       "      <th>bidRate6</th>\n",
       "      <th>bidRate7</th>\n",
       "      <th>bidRate8</th>\n",
       "      <th>bidRate9</th>\n",
       "      <th>bidRate10</th>\n",
       "      <th>bidRate11</th>\n",
       "      <th>bidRate12</th>\n",
       "      <th>bidRate13</th>\n",
       "      <th>bidRate14</th>\n",
       "      <th>bidSize0</th>\n",
       "      <th>bidSize1</th>\n",
       "      <th>bidSize2</th>\n",
       "      <th>bidSize3</th>\n",
       "      <th>bidSize4</th>\n",
       "      <th>bidSize5</th>\n",
       "      <th>bidSize6</th>\n",
       "      <th>bidSize7</th>\n",
       "      <th>bidSize8</th>\n",
       "      <th>bidSize9</th>\n",
       "      <th>bidSize10</th>\n",
       "      <th>bidSize11</th>\n",
       "      <th>bidSize12</th>\n",
       "      <th>bidSize13</th>\n",
       "      <th>bidSize14</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1619.5</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>1621.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1615.0</td>\n",
       "      <td>1614.0</td>\n",
       "      <td>1613.0</td>\n",
       "      <td>1612.0</td>\n",
       "      <td>1611.0</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>1607.0</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>1605.0</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>1603.0</td>\n",
       "      <td>1602.0</td>\n",
       "      <td>1601.5</td>\n",
       "      <td>1601.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1619.5</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>1621.0</td>\n",
       "      <td>1621.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1615.0</td>\n",
       "      <td>1614.0</td>\n",
       "      <td>1613.0</td>\n",
       "      <td>1612.0</td>\n",
       "      <td>1611.0</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>1607.0</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>1605.0</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>1603.0</td>\n",
       "      <td>1602.0</td>\n",
       "      <td>1601.5</td>\n",
       "      <td>1601.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1619.5</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>1621.0</td>\n",
       "      <td>1621.5</td>\n",
       "      <td>1622.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1615.0</td>\n",
       "      <td>1614.0</td>\n",
       "      <td>1613.0</td>\n",
       "      <td>1612.0</td>\n",
       "      <td>1611.0</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>1607.0</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>1605.0</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>1603.0</td>\n",
       "      <td>1602.0</td>\n",
       "      <td>1601.5</td>\n",
       "      <td>1601.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1619.5</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>1621.0</td>\n",
       "      <td>1621.5</td>\n",
       "      <td>1622.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1615.0</td>\n",
       "      <td>1614.0</td>\n",
       "      <td>1613.0</td>\n",
       "      <td>1612.0</td>\n",
       "      <td>1611.0</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>1607.0</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>1605.0</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>1603.0</td>\n",
       "      <td>1602.0</td>\n",
       "      <td>1601.5</td>\n",
       "      <td>1601.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1619.5</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>1621.0</td>\n",
       "      <td>1621.5</td>\n",
       "      <td>1622.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1615.0</td>\n",
       "      <td>1614.0</td>\n",
       "      <td>1613.0</td>\n",
       "      <td>1612.0</td>\n",
       "      <td>1611.0</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>1607.0</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>1605.0</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>1603.0</td>\n",
       "      <td>1602.0</td>\n",
       "      <td>1601.5</td>\n",
       "      <td>1601.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   askRate0  askRate1  askRate2  askRate3  askRate4  askRate5  askRate6  \\\n",
       "0    1619.5    1620.0    1621.0       0.0       0.0       0.0       0.0   \n",
       "1    1619.5    1620.0    1621.0    1621.5       0.0       0.0       0.0   \n",
       "2    1619.5    1620.0    1621.0    1621.5    1622.0       0.0       0.0   \n",
       "3    1619.5    1620.0    1621.0    1621.5    1622.0       0.0       0.0   \n",
       "4    1619.5    1620.0    1621.0    1621.5    1622.0       0.0       0.0   \n",
       "\n",
       "   askRate7  askRate8  askRate9  askRate10  askRate11  askRate12  askRate13  \\\n",
       "0       0.0       0.0       0.0        0.0        0.0        0.0        0.0   \n",
       "1       0.0       0.0       0.0        0.0        0.0        0.0        0.0   \n",
       "2       0.0       0.0       0.0        0.0        0.0        0.0        0.0   \n",
       "3       0.0       0.0       0.0        0.0        0.0        0.0        0.0   \n",
       "4       0.0       0.0       0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   askRate14  askSize0  askSize1  askSize2  askSize3  askSize4  askSize5  \\\n",
       "0        0.0         1        10        24         0         0         0   \n",
       "1        0.0         1        10        24         5         0         0   \n",
       "2        0.0         1        10        24         5         2         0   \n",
       "3        0.0         1        10        24         5        22         0   \n",
       "4        0.0         1        10        24         5        32         0   \n",
       "\n",
       "   askSize6  askSize7  askSize8  askSize9  askSize10  askSize11  askSize12  \\\n",
       "0         0         0         0         0          0          0          0   \n",
       "1         0         0         0         0          0          0          0   \n",
       "2         0         0         0         0          0          0          0   \n",
       "3         0         0         0         0          0          0          0   \n",
       "4         0         0         0         0          0          0          0   \n",
       "\n",
       "   askSize13  askSize14  bidRate0  bidRate1  bidRate2  bidRate3  bidRate4  \\\n",
       "0          0          0    1615.0    1614.0    1613.0    1612.0    1611.0   \n",
       "1          0          0    1615.0    1614.0    1613.0    1612.0    1611.0   \n",
       "2          0          0    1615.0    1614.0    1613.0    1612.0    1611.0   \n",
       "3          0          0    1615.0    1614.0    1613.0    1612.0    1611.0   \n",
       "4          0          0    1615.0    1614.0    1613.0    1612.0    1611.0   \n",
       "\n",
       "   bidRate5  bidRate6  bidRate7  bidRate8  bidRate9  bidRate10  bidRate11  \\\n",
       "0    1610.0    1607.0    1606.0    1605.0    1604.0     1603.0     1602.0   \n",
       "1    1610.0    1607.0    1606.0    1605.0    1604.0     1603.0     1602.0   \n",
       "2    1610.0    1607.0    1606.0    1605.0    1604.0     1603.0     1602.0   \n",
       "3    1610.0    1607.0    1606.0    1605.0    1604.0     1603.0     1602.0   \n",
       "4    1610.0    1607.0    1606.0    1605.0    1604.0     1603.0     1602.0   \n",
       "\n",
       "   bidRate12  bidRate13  bidRate14  bidSize0  bidSize1  bidSize2  bidSize3  \\\n",
       "0     1601.5     1601.0     1600.0         7        10         1        10   \n",
       "1     1601.5     1601.0     1600.0         7        10         1        10   \n",
       "2     1601.5     1601.0     1600.0         7        10         1        10   \n",
       "3     1601.5     1601.0     1600.0         7        10         1        10   \n",
       "4     1601.5     1601.0     1600.0         7        10         1        10   \n",
       "\n",
       "   bidSize4  bidSize5  bidSize6  bidSize7  bidSize8  bidSize9  bidSize10  \\\n",
       "0        20         3        20        27        11        14         35   \n",
       "1        20         3        20        27        11        14         35   \n",
       "2        20         3        20        27        11        14         35   \n",
       "3        20         3        20        27        11        14         35   \n",
       "4        20         3        20        27        11        14         35   \n",
       "\n",
       "   bidSize11  bidSize12  bidSize13  bidSize14    y  \n",
       "0         10          1         10         13 -0.5  \n",
       "1         10          1         10         13 -0.5  \n",
       "2         10          1         10         13 -0.5  \n",
       "3         10          1         10         13 -0.5  \n",
       "4         10          1         10         13 -0.5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor = FeatureExtractor('data/data.pkl')\n",
    "data = feature_extractor.data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ask_rate_0</th>\n",
       "      <th>mid_price</th>\n",
       "      <th>mid_price_log</th>\n",
       "      <th>ask_len</th>\n",
       "      <th>bid_len</th>\n",
       "      <th>wap0</th>\n",
       "      <th>wap1</th>\n",
       "      <th>len_ratio</th>\n",
       "      <th>volume_imbalance</th>\n",
       "      <th>volume_imbalance_1</th>\n",
       "      <th>volume_imbalance_2</th>\n",
       "      <th>increased_ask_counts</th>\n",
       "      <th>increased_ask_rank</th>\n",
       "      <th>decreased_ask_counts</th>\n",
       "      <th>decreased_ask_rank</th>\n",
       "      <th>increased_bid_counts</th>\n",
       "      <th>increased_bid_rank</th>\n",
       "      <th>decreased_bid_counts</th>\n",
       "      <th>decreased_bid_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1619.5</td>\n",
       "      <td>1617.25</td>\n",
       "      <td>7.389101</td>\n",
       "      <td>35</td>\n",
       "      <td>192</td>\n",
       "      <td>1618.9375</td>\n",
       "      <td>1617.0</td>\n",
       "      <td>0.182292</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1619.5</td>\n",
       "      <td>1617.25</td>\n",
       "      <td>7.389101</td>\n",
       "      <td>40</td>\n",
       "      <td>192</td>\n",
       "      <td>1618.9375</td>\n",
       "      <td>1617.0</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1619.5</td>\n",
       "      <td>1617.25</td>\n",
       "      <td>7.389101</td>\n",
       "      <td>42</td>\n",
       "      <td>192</td>\n",
       "      <td>1618.9375</td>\n",
       "      <td>1617.0</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1619.5</td>\n",
       "      <td>1617.25</td>\n",
       "      <td>7.389101</td>\n",
       "      <td>62</td>\n",
       "      <td>192</td>\n",
       "      <td>1618.9375</td>\n",
       "      <td>1617.0</td>\n",
       "      <td>0.322917</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1619.5</td>\n",
       "      <td>1617.25</td>\n",
       "      <td>7.389101</td>\n",
       "      <td>72</td>\n",
       "      <td>192</td>\n",
       "      <td>1618.9375</td>\n",
       "      <td>1617.0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ask_rate_0  mid_price  mid_price_log  ask_len  bid_len       wap0    wap1  \\\n",
       "0      1619.5    1617.25       7.389101       35      192  1618.9375  1617.0   \n",
       "1      1619.5    1617.25       7.389101       40      192  1618.9375  1617.0   \n",
       "2      1619.5    1617.25       7.389101       42      192  1618.9375  1617.0   \n",
       "3      1619.5    1617.25       7.389101       62      192  1618.9375  1617.0   \n",
       "4      1619.5    1617.25       7.389101       72      192  1618.9375  1617.0   \n",
       "\n",
       "   len_ratio  volume_imbalance  volume_imbalance_1  volume_imbalance_2  \\\n",
       "0   0.182292              0.75                 0.0               -0.92   \n",
       "1   0.208333              0.75                 0.0               -0.92   \n",
       "2   0.218750              0.75                 0.0               -0.92   \n",
       "3   0.322917              0.75                 0.0               -0.92   \n",
       "4   0.375000              0.75                 0.0               -0.92   \n",
       "\n",
       "   increased_ask_counts  increased_ask_rank  decreased_ask_counts  \\\n",
       "0                     0                  15                     0   \n",
       "1                     1                   3                     0   \n",
       "2                     1                   4                     0   \n",
       "3                     1                   4                     0   \n",
       "4                     1                   4                     0   \n",
       "\n",
       "   decreased_ask_rank  increased_bid_counts  increased_bid_rank  \\\n",
       "0                  15                     0                  15   \n",
       "1                  15                     0                  15   \n",
       "2                  15                     0                  15   \n",
       "3                  15                     0                  15   \n",
       "4                  15                     0                  15   \n",
       "\n",
       "   decreased_bid_counts  decreased_bid_rank  \n",
       "0                     0                  15  \n",
       "1                     0                  15  \n",
       "2                     0                  15  \n",
       "3                     0                  15  \n",
       "4                     0                  15  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_features = feature_extractor.get_base_features()\n",
    "base_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0506b0b09cce4062ad7e8d787df1469a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | dataset   | metric_name   |   fold_0 |   fold_1 |   fold_2 |   fold_3 |   fold_4 |\n",
      "|---:|:----------|:--------------|---------:|---------:|---------:|---------:|---------:|\n",
      "|  0 | val       | mse           |    0.503 |    0.46  |    0.461 |    0.621 |    0.575 |\n",
      "|  1 | val       | corr          |    0.139 |    0.164 |    0.138 |    0.125 |    0.121 |\n",
      "|  2 | test      | mse           |    0.333 |    0.333 |    0.332 |    0.333 |    0.332 |\n",
      "|  3 | test      | corr          |    0.151 |    0.151 |    0.151 |    0.151 |    0.152 |\n",
      "        \t\tVal  corr averaged: 0.137\n",
      "        \t\tVal   MSE averaged: 0.524\n",
      "        \t\tTest corr averaged: 0.151\n",
      "        \t\tTest  MSE averaged: 0.333\n",
      "        ------------------------------------------------------------------\n",
      "        \t\tAveraged test  MSE: 0.333\n",
      "        \t\tAveraged test corr: 0.151\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "base_features = feature_extractor.get_base_features()\n",
    "\n",
    "time_folds = TimeFolds(n_folds=5, minifold_size=60000, neutral_ratio=0.15, test_ratio=0.25, test_neutral_ratio=0.1)\n",
    "time_folds.fit(base_features, data.y)\n",
    "\n",
    "cross_val_runner = CrossValRunner(time_folds, **MODEL_CONFIGS['default_ridge'])\n",
    "cross_val_runner.fit(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xtx.feature_extractor import FeatureExtractor\n",
    "fe = FeatureExtractor('data/data.pkl')\n",
    "base_features_v2 = fe.get_base_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "118055a4eef346cfbbd3c395569c78d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | dataset   | metric_name   |   fold_0 |   fold_1 |   fold_2 |   fold_3 |   fold_4 |\n",
      "|---:|:----------|:--------------|---------:|---------:|---------:|---------:|---------:|\n",
      "|  0 | val       | mse           |    0.503 |    0.46  |    0.461 |    0.62  |    0.575 |\n",
      "|  1 | val       | corr          |    0.135 |    0.164 |    0.139 |    0.127 |    0.121 |\n",
      "|  2 | test      | mse           |    0.459 |    0.443 |    0.452 |    0.482 |    0.469 |\n",
      "|  3 | test      | corr          |    0.039 |    0.04  |    0.04  |    0.037 |    0.037 |\n",
      "        \t\tVal  corr averaged: 0.137\n",
      "        \t\tVal   MSE averaged: 0.524\n",
      "        \t\tTest corr averaged: 0.039\n",
      "        \t\tTest  MSE averaged: 0.461\n",
      "        ------------------------------------------------------------------\n",
      "        \t\tAveraged test  MSE: 0.460\n",
      "        \t\tAveraged test corr: 0.038\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "time_folds.fit(base_features_v2, data.y)\n",
    "\n",
    "cross_val_runner = CrossValRunner(time_folds, **MODEL_CONFIGS['default_ridge'])\n",
    "cross_val_runner.fit(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.75 ms, sys: 5.42 ms, total: 14.2 ms\n",
      "Wall time: 13 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "base_features['minifold'] = np.arange(base_features.shape[0]) // 5\n",
    "group = base_features.groupby('minifold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df105898cf284ee68079c282d77ce0cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ask_flatten_mean_5</th>\n",
       "      <th>ask_flatten_std_5</th>\n",
       "      <th>ask_flatten_skew_5</th>\n",
       "      <th>ask_flatten_kurtosis_5</th>\n",
       "      <th>bid_flatten_mean_5</th>\n",
       "      <th>bid_flatten_skew_5</th>\n",
       "      <th>bid_flatten_kurtosis_5</th>\n",
       "      <th>flatten_spread_5_mean</th>\n",
       "      <th>wap_flatten_5</th>\n",
       "      <th>bid_flatten_std_5</th>\n",
       "      <th>ask_flatten_mean_15</th>\n",
       "      <th>ask_flatten_median_15</th>\n",
       "      <th>ask_flatten_std_15</th>\n",
       "      <th>ask_flatten_iqr_15</th>\n",
       "      <th>ask_flatten_skew_15</th>\n",
       "      <th>ask_flatten_kurtosis_15</th>\n",
       "      <th>bid_flatten_mean_15</th>\n",
       "      <th>bid_flatten_median_15</th>\n",
       "      <th>bid_flatten_iqr_15</th>\n",
       "      <th>bid_flatten_skew_15</th>\n",
       "      <th>bid_flatten_kurtosis_15</th>\n",
       "      <th>flatten_spread_15_mean</th>\n",
       "      <th>flatten_spread_15_median</th>\n",
       "      <th>wap_flatten_15</th>\n",
       "      <th>bid_flatten_std_15</th>\n",
       "      <th>ask_flatten_mean_50</th>\n",
       "      <th>ask_flatten_median_50</th>\n",
       "      <th>ask_flatten_std_50</th>\n",
       "      <th>ask_flatten_iqr_50</th>\n",
       "      <th>ask_flatten_skew_50</th>\n",
       "      <th>ask_flatten_kurtosis_50</th>\n",
       "      <th>bid_flatten_mean_50</th>\n",
       "      <th>bid_flatten_median_50</th>\n",
       "      <th>bid_flatten_iqr_50</th>\n",
       "      <th>bid_flatten_skew_50</th>\n",
       "      <th>bid_flatten_kurtosis_50</th>\n",
       "      <th>flatten_spread_50_mean</th>\n",
       "      <th>flatten_spread_50_median</th>\n",
       "      <th>wap_flatten_50</th>\n",
       "      <th>ask_flatten_len_100</th>\n",
       "      <th>ask_flatten_mean_100</th>\n",
       "      <th>ask_flatten_median_100</th>\n",
       "      <th>ask_flatten_std_100</th>\n",
       "      <th>ask_flatten_iqr_100</th>\n",
       "      <th>ask_flatten_skew_100</th>\n",
       "      <th>ask_flatten_kurtosis_100</th>\n",
       "      <th>bid_flatten_len_100</th>\n",
       "      <th>bid_flatten_mean_100</th>\n",
       "      <th>bid_flatten_median_100</th>\n",
       "      <th>bid_flatten_iqr_100</th>\n",
       "      <th>bid_flatten_skew_100</th>\n",
       "      <th>bid_flatten_kurtosis_100</th>\n",
       "      <th>flatten_spread_100_mean</th>\n",
       "      <th>flatten_spread_100_median</th>\n",
       "      <th>wap_flatten_100</th>\n",
       "      <th>bid_flatten_std_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1619.900024</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1615.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.003034</td>\n",
       "      <td>1617.449951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1620.233276</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>0.478423</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.779935</td>\n",
       "      <td>-0.835753</td>\n",
       "      <td>1614.466675</td>\n",
       "      <td>1614.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.133631</td>\n",
       "      <td>-1.982143</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>1617.349976</td>\n",
       "      <td>0.498888</td>\n",
       "      <td>1620.671387</td>\n",
       "      <td>1621.0</td>\n",
       "      <td>0.491976</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.907700</td>\n",
       "      <td>-0.954024</td>\n",
       "      <td>1612.359985</td>\n",
       "      <td>1612.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.483242</td>\n",
       "      <td>-1.276247</td>\n",
       "      <td>0.005155</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>1617.249023</td>\n",
       "      <td>35</td>\n",
       "      <td>1620.671387</td>\n",
       "      <td>1621.0</td>\n",
       "      <td>0.491976</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.907700</td>\n",
       "      <td>-0.954024</td>\n",
       "      <td>100</td>\n",
       "      <td>1609.400024</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.302392</td>\n",
       "      <td>-1.384458</td>\n",
       "      <td>0.007003</td>\n",
       "      <td>0.006832</td>\n",
       "      <td>1617.749146</td>\n",
       "      <td>3.209361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1619.900024</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1615.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.003034</td>\n",
       "      <td>1617.449951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1620.233276</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>0.478423</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.779935</td>\n",
       "      <td>-0.835753</td>\n",
       "      <td>1614.466675</td>\n",
       "      <td>1614.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.133631</td>\n",
       "      <td>-1.982143</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>1617.349976</td>\n",
       "      <td>0.498888</td>\n",
       "      <td>1620.775024</td>\n",
       "      <td>1621.0</td>\n",
       "      <td>0.535607</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.740104</td>\n",
       "      <td>-0.663021</td>\n",
       "      <td>1612.359985</td>\n",
       "      <td>1612.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.483242</td>\n",
       "      <td>-1.276247</td>\n",
       "      <td>0.005219</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>1617.035034</td>\n",
       "      <td>40</td>\n",
       "      <td>1620.775024</td>\n",
       "      <td>1621.0</td>\n",
       "      <td>0.535607</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.740104</td>\n",
       "      <td>-0.663021</td>\n",
       "      <td>100</td>\n",
       "      <td>1609.400024</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.302392</td>\n",
       "      <td>-1.384458</td>\n",
       "      <td>0.007068</td>\n",
       "      <td>0.006832</td>\n",
       "      <td>1617.525024</td>\n",
       "      <td>3.209361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1619.900024</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1615.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.003034</td>\n",
       "      <td>1617.449951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1620.233276</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>0.478423</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.779935</td>\n",
       "      <td>-0.835753</td>\n",
       "      <td>1614.466675</td>\n",
       "      <td>1614.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.133631</td>\n",
       "      <td>-1.982143</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>1617.349976</td>\n",
       "      <td>0.498888</td>\n",
       "      <td>1620.833374</td>\n",
       "      <td>1621.0</td>\n",
       "      <td>0.584183</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.404726</td>\n",
       "      <td>-0.404813</td>\n",
       "      <td>1612.359985</td>\n",
       "      <td>1612.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.483242</td>\n",
       "      <td>-1.276247</td>\n",
       "      <td>0.005255</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>1616.965088</td>\n",
       "      <td>42</td>\n",
       "      <td>1620.833374</td>\n",
       "      <td>1621.0</td>\n",
       "      <td>0.584183</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.404726</td>\n",
       "      <td>-0.404813</td>\n",
       "      <td>100</td>\n",
       "      <td>1609.400024</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.302392</td>\n",
       "      <td>-1.384458</td>\n",
       "      <td>0.007104</td>\n",
       "      <td>0.006832</td>\n",
       "      <td>1617.451660</td>\n",
       "      <td>3.209361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1619.900024</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1615.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.003034</td>\n",
       "      <td>1617.449951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1620.233276</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>0.478423</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.779935</td>\n",
       "      <td>-0.835753</td>\n",
       "      <td>1614.466675</td>\n",
       "      <td>1614.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.133631</td>\n",
       "      <td>-1.982143</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>1617.349976</td>\n",
       "      <td>0.498888</td>\n",
       "      <td>1621.020020</td>\n",
       "      <td>1621.0</td>\n",
       "      <td>0.685274</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.258492</td>\n",
       "      <td>-0.673599</td>\n",
       "      <td>1612.359985</td>\n",
       "      <td>1612.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.483242</td>\n",
       "      <td>-1.276247</td>\n",
       "      <td>0.005371</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>1616.689941</td>\n",
       "      <td>62</td>\n",
       "      <td>1621.209717</td>\n",
       "      <td>1621.0</td>\n",
       "      <td>0.727060</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.500972</td>\n",
       "      <td>-0.770738</td>\n",
       "      <td>100</td>\n",
       "      <td>1609.400024</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.302392</td>\n",
       "      <td>-1.384458</td>\n",
       "      <td>0.007338</td>\n",
       "      <td>0.006832</td>\n",
       "      <td>1616.689941</td>\n",
       "      <td>3.209361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1619.900024</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1615.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.003034</td>\n",
       "      <td>1617.449951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1620.233276</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>0.478423</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.779935</td>\n",
       "      <td>-0.835753</td>\n",
       "      <td>1614.466675</td>\n",
       "      <td>1614.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.133631</td>\n",
       "      <td>-1.982143</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>1617.349976</td>\n",
       "      <td>0.498888</td>\n",
       "      <td>1621.020020</td>\n",
       "      <td>1621.0</td>\n",
       "      <td>0.685274</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.258492</td>\n",
       "      <td>-0.673599</td>\n",
       "      <td>1612.359985</td>\n",
       "      <td>1612.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.483242</td>\n",
       "      <td>-1.276247</td>\n",
       "      <td>0.005371</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>1616.689941</td>\n",
       "      <td>72</td>\n",
       "      <td>1621.319458</td>\n",
       "      <td>1621.5</td>\n",
       "      <td>0.727942</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.707885</td>\n",
       "      <td>-0.606647</td>\n",
       "      <td>100</td>\n",
       "      <td>1609.400024</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.302392</td>\n",
       "      <td>-1.384458</td>\n",
       "      <td>0.007406</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>1616.329956</td>\n",
       "      <td>3.209361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ask_flatten_mean_5  ask_flatten_std_5  ask_flatten_skew_5  \\\n",
       "0         1619.900024                0.2                -1.5   \n",
       "1         1619.900024                0.2                -1.5   \n",
       "2         1619.900024                0.2                -1.5   \n",
       "3         1619.900024                0.2                -1.5   \n",
       "4         1619.900024                0.2                -1.5   \n",
       "\n",
       "   ask_flatten_kurtosis_5  bid_flatten_mean_5  bid_flatten_skew_5  \\\n",
       "0                    0.25              1615.0                 0.0   \n",
       "1                    0.25              1615.0                 0.0   \n",
       "2                    0.25              1615.0                 0.0   \n",
       "3                    0.25              1615.0                 0.0   \n",
       "4                    0.25              1615.0                 0.0   \n",
       "\n",
       "   bid_flatten_kurtosis_5  flatten_spread_5_mean  wap_flatten_5  \\\n",
       "0                    -3.0               0.003034    1617.449951   \n",
       "1                    -3.0               0.003034    1617.449951   \n",
       "2                    -3.0               0.003034    1617.449951   \n",
       "3                    -3.0               0.003034    1617.449951   \n",
       "4                    -3.0               0.003034    1617.449951   \n",
       "\n",
       "   bid_flatten_std_5  ask_flatten_mean_15  ask_flatten_median_15  \\\n",
       "0                0.0          1620.233276                 1620.0   \n",
       "1                0.0          1620.233276                 1620.0   \n",
       "2                0.0          1620.233276                 1620.0   \n",
       "3                0.0          1620.233276                 1620.0   \n",
       "4                0.0          1620.233276                 1620.0   \n",
       "\n",
       "   ask_flatten_std_15  ask_flatten_iqr_15  ask_flatten_skew_15  \\\n",
       "0            0.478423                 0.5             0.779935   \n",
       "1            0.478423                 0.5             0.779935   \n",
       "2            0.478423                 0.5             0.779935   \n",
       "3            0.478423                 0.5             0.779935   \n",
       "4            0.478423                 0.5             0.779935   \n",
       "\n",
       "   ask_flatten_kurtosis_15  bid_flatten_mean_15  bid_flatten_median_15  \\\n",
       "0                -0.835753          1614.466675                 1614.0   \n",
       "1                -0.835753          1614.466675                 1614.0   \n",
       "2                -0.835753          1614.466675                 1614.0   \n",
       "3                -0.835753          1614.466675                 1614.0   \n",
       "4                -0.835753          1614.466675                 1614.0   \n",
       "\n",
       "   bid_flatten_iqr_15  bid_flatten_skew_15  bid_flatten_kurtosis_15  \\\n",
       "0                 1.0             0.133631                -1.982143   \n",
       "1                 1.0             0.133631                -1.982143   \n",
       "2                 1.0             0.133631                -1.982143   \n",
       "3                 1.0             0.133631                -1.982143   \n",
       "4                 1.0             0.133631                -1.982143   \n",
       "\n",
       "   flatten_spread_15_mean  flatten_spread_15_median  wap_flatten_15  \\\n",
       "0                0.003572                  0.003717     1617.349976   \n",
       "1                0.003572                  0.003717     1617.349976   \n",
       "2                0.003572                  0.003717     1617.349976   \n",
       "3                0.003572                  0.003717     1617.349976   \n",
       "4                0.003572                  0.003717     1617.349976   \n",
       "\n",
       "   bid_flatten_std_15  ask_flatten_mean_50  ask_flatten_median_50  \\\n",
       "0            0.498888          1620.671387                 1621.0   \n",
       "1            0.498888          1620.775024                 1621.0   \n",
       "2            0.498888          1620.833374                 1621.0   \n",
       "3            0.498888          1621.020020                 1621.0   \n",
       "4            0.498888          1621.020020                 1621.0   \n",
       "\n",
       "   ask_flatten_std_50  ask_flatten_iqr_50  ask_flatten_skew_50  \\\n",
       "0            0.491976                1.00            -0.907700   \n",
       "1            0.535607                1.00            -0.740104   \n",
       "2            0.584183                0.75            -0.404726   \n",
       "3            0.685274                0.50            -0.258492   \n",
       "4            0.685274                0.50            -0.258492   \n",
       "\n",
       "   ask_flatten_kurtosis_50  bid_flatten_mean_50  bid_flatten_median_50  \\\n",
       "0                -0.954024          1612.359985                 1612.0   \n",
       "1                -0.663021          1612.359985                 1612.0   \n",
       "2                -0.404813          1612.359985                 1612.0   \n",
       "3                -0.673599          1612.359985                 1612.0   \n",
       "4                -0.673599          1612.359985                 1612.0   \n",
       "\n",
       "   bid_flatten_iqr_50  bid_flatten_skew_50  bid_flatten_kurtosis_50  \\\n",
       "0                 3.0             0.483242                -1.276247   \n",
       "1                 3.0             0.483242                -1.276247   \n",
       "2                 3.0             0.483242                -1.276247   \n",
       "3                 3.0             0.483242                -1.276247   \n",
       "4                 3.0             0.483242                -1.276247   \n",
       "\n",
       "   flatten_spread_50_mean  flatten_spread_50_median  wap_flatten_50  \\\n",
       "0                0.005155                  0.005583     1617.249023   \n",
       "1                0.005219                  0.005583     1617.035034   \n",
       "2                0.005255                  0.005583     1616.965088   \n",
       "3                0.005371                  0.005583     1616.689941   \n",
       "4                0.005371                  0.005583     1616.689941   \n",
       "\n",
       "   ask_flatten_len_100  ask_flatten_mean_100  ask_flatten_median_100  \\\n",
       "0                   35           1620.671387                  1621.0   \n",
       "1                   40           1620.775024                  1621.0   \n",
       "2                   42           1620.833374                  1621.0   \n",
       "3                   62           1621.209717                  1621.0   \n",
       "4                   72           1621.319458                  1621.5   \n",
       "\n",
       "   ask_flatten_std_100  ask_flatten_iqr_100  ask_flatten_skew_100  \\\n",
       "0             0.491976                 1.00             -0.907700   \n",
       "1             0.535607                 1.00             -0.740104   \n",
       "2             0.584183                 0.75             -0.404726   \n",
       "3             0.727060                 1.00             -0.500972   \n",
       "4             0.727942                 1.00             -0.707885   \n",
       "\n",
       "   ask_flatten_kurtosis_100  bid_flatten_len_100  bid_flatten_mean_100  \\\n",
       "0                 -0.954024                  100           1609.400024   \n",
       "1                 -0.663021                  100           1609.400024   \n",
       "2                 -0.404813                  100           1609.400024   \n",
       "3                 -0.770738                  100           1609.400024   \n",
       "4                 -0.606647                  100           1609.400024   \n",
       "\n",
       "   bid_flatten_median_100  bid_flatten_iqr_100  bid_flatten_skew_100  \\\n",
       "0                  1610.0                  6.0              0.302392   \n",
       "1                  1610.0                  6.0              0.302392   \n",
       "2                  1610.0                  6.0              0.302392   \n",
       "3                  1610.0                  6.0              0.302392   \n",
       "4                  1610.0                  6.0              0.302392   \n",
       "\n",
       "   bid_flatten_kurtosis_100  flatten_spread_100_mean  \\\n",
       "0                 -1.384458                 0.007003   \n",
       "1                 -1.384458                 0.007068   \n",
       "2                 -1.384458                 0.007104   \n",
       "3                 -1.384458                 0.007338   \n",
       "4                 -1.384458                 0.007406   \n",
       "\n",
       "   flatten_spread_100_median  wap_flatten_100  bid_flatten_std_100  \n",
       "0                   0.006832      1617.749146             3.209361  \n",
       "1                   0.006832      1617.525024             3.209361  \n",
       "2                   0.006832      1617.451660             3.209361  \n",
       "3                   0.006832      1616.689941             3.209361  \n",
       "4                   0.007143      1616.329956             3.209361  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_list = []\n",
    "for n_per_row in tqdm((5, 15, 50, 100)):\n",
    "    current_features = pd.read_pickle(f'../new_artefacts/features_{n_per_row}.pkl')\n",
    "    if n_per_row == 3:\n",
    "        selected_cols = ['ask_flatten_mean_3', 'bid_flatten_mean_3', 'wap_flatten_3']\n",
    "        drop_cols = [col for col in current_features.columns if col not in selected_cols]\n",
    "    elif n_per_row < 10:\n",
    "        drop_cols = [\n",
    "            f'flatten_spread_{n_per_row}_median',\n",
    "            f'ask_flatten_iqr_{n_per_row}',\n",
    "            f'bid_flatten_iqr_{n_per_row}',\n",
    "            f'ask_flatten_median_{n_per_row}',\n",
    "            f'bid_flatten_median_{n_per_row}',\n",
    "            f'ask_flatten_len_{n_per_row}',\n",
    "            f'bid_flatten_len_{n_per_row}',\n",
    "        ]\n",
    "    elif n_per_row < 100:\n",
    "        drop_cols = [f'ask_flatten_len_{n_per_row}', f'bid_flatten_len_{n_per_row}']\n",
    "    else:\n",
    "        drop_cols = []\n",
    "        \n",
    "    current_features.drop(drop_cols, axis=1, inplace=True)\n",
    "    for col in current_features.columns:\n",
    "        if current_features[col].dtype == np.float64:\n",
    "            current_features[col] = current_features[col].astype(np.float32)\n",
    "    features_list.append(current_features)\n",
    "topk_features = pd.concat(features_list, axis=1)\n",
    "\n",
    "# usecols = list(set(usecols))\n",
    "topk_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_usecols = [\n",
    "    # 'ask_flatten_mean_5',\n",
    "    'bid_flatten_mean_5',\n",
    "    'wap_flatten_15',\n",
    "    'ask_flatten_skew_50',\n",
    "    'bid_flatten_mean_50',\n",
    "    'bid_flatten_kurtosis_50',\n",
    "    'ask_flatten_mean_100',\n",
    "    'ask_flatten_iqr_100',\n",
    "]\n",
    "\n",
    "base_features = make_base_features(data)\n",
    "from xtx.time_folds import TimeFolds\n",
    "time_folds = TimeFolds(n_folds=5, minifold_size=60000, neutral_ratio=0., test_ratio=0.25, test_neutral_ratio=0.1)\n",
    "\n",
    "x = pd.concat((base_features, topk_features.loc[:, topk_usecols]), axis=1)\n",
    "\n",
    "# time_folds.fit(x, data.y)\n",
    "# cross_val_runner = CrossValRunner(time_folds, **MODEL_CONFIGS['default_ridge'])\n",
    "# cross_val_runner.fit(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_folds = TimeFolds(n_folds=5, minifold_size=60000, neutral_ratio=0., test_ratio=0.25, test_neutral_ratio=0.1)\n",
    "# time_folds.fit(x, data.y)\n",
    "\n",
    "# cross_val_runner = CrossValRunner(time_folds, **MODEL_CONFIGS['default_lgbm'])\n",
    "# cross_val_runner.fit(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_features = make_base_features(data)\n",
    "from xtx.time_folds import TimeFolds\n",
    "time_folds = TimeFolds(n_folds=5, minifold_size=60000, neutral_ratio=0., test_ratio=0.25, test_neutral_ratio=0.1)\n",
    "# time_folds.fit(base_features, data.y)\n",
    "# ridge_eval(time_folds, 3, 100)\n",
    "\n",
    "base_features = pd.concat((base_features, topk_features.loc[:, topk_usecols]), axis=1)\n",
    "for window in (3, 5, 10, 20, 40, 80):\n",
    "    # ask bid size changes\n",
    "    ask_size_diff = data[ask_size_cols].diff(window)\n",
    "    bid_size_diff = data[bid_size_cols].diff(window)\n",
    "\n",
    "    ask_size_diff.columns = np.arange(15)\n",
    "    base_features['increased_ask_counts'] = (ask_size_diff> 0).sum(axis=1)\n",
    "    base_features['decreased_ask_counts'] = (ask_size_diff < 0).sum(axis=1)\n",
    "\n",
    "    # base_features[f'increased_ask_counts_{window}_volume'] = (ask_size_diff * (ask_size_diff > 0)).sum(1)\n",
    "    # base_features[f'decreased_ask_counts_{window}_volume'] = (-ask_size_diff * (ask_size_diff < 0)).sum(1)\n",
    "    # (ask_size_diff > 0) * ask_size_diff\n",
    "\n",
    "    bid_size_diff.columns = np.arange(15)\n",
    "    base_features['increased_bid_counts'] = (bid_size_diff > 0).sum(axis=1)\n",
    "    base_features['decreased_bid_counts'] = (bid_size_diff < 0).sum(axis=1)    \n",
    "    \n",
    "    base_features[f'volume_imbalance_{window}'] = base_features['volume_imbalance'].diff(window)\n",
    "    base_features[f'mid_price_log_{window}'] = base_features[f'mid_price_log'].diff(window)\n",
    "\n",
    "for window in (40, 80):\n",
    "    # base_features[f'mid_price_log_std_{window}'] = base_features[f'mid_price_log'].rolling(window).std()\n",
    "    # base_features[f'mid_price_log_mean_diff_{window}'] = base_features[f'mid_price_log'].rolling(window).mean() - base_features[f'mid_price_log']\n",
    "    base_features[f'mid_price_log_max_diff_{window}'] = base_features[f'mid_price_log'].rolling(window).max() - base_features[f'mid_price_log']\n",
    "    # base_features[f'mid_price_log_std_{window}'] = base_features[f'mid_price_log'].diff(window).rolling(window).std()\n",
    "    \n",
    "for window in (10, 20, 40, 80):    \n",
    "    base_features[f'wap0_{window}_mean'] = base_features['wap0'].rolling(window).mean()\n",
    "    base_features[f'wap0_{window}_std'] = base_features['wap0'].rolling(window).std() #overfit?\n",
    "    base_features[f'wap0_{window}_max'] = base_features['wap0'].rolling(window).max() #overfit?\n",
    "\n",
    "    # base_features[f'wap1_{window}_mean'] = base_features['wap1'].rolling(window).mean()\n",
    "    # base_features[f'wap1_{window}_std'] = base_features['wap1'].rolling(window).std() #overfit?\n",
    "    # base_features[f'wap1_{window}_max'] = base_features['wap1'].rolling(window).max() #overfit?\n",
    "\n",
    "    base_features[f'volume_imbalance_{window}_mean'] = base_features['volume_imbalance'].rolling(window).mean()\n",
    "    base_features[f'volume_imbalance_{window}_max'] = base_features['volume_imbalance'].rolling(window).max()\n",
    "    base_features[f'volume_imbalance_{window}_std'] = base_features['volume_imbalance'].rolling(window).std()\n",
    "    base_features[f'volume_imbalance_{window}_skew'] = base_features['volume_imbalance'].rolling(window).skew()\n",
    "    # base_features[f'volume_imbalance_{window}_iqr'] = base_features['volume_imbalance'].rolling(window).quantile(0.75) - \\\n",
    "        # base_features['volume_imbalance'].rolling(window).quantile(0.25)\n",
    "    base_features[f'len_ratio_{window}_mean'] = base_features['len_ratio'].rolling(window).mean()\n",
    "    base_features[f'len_ratio_{window}_std'] = base_features['len_ratio'].rolling(window).std()\n",
    "    # base_features[f'len_ratio_{window}_max'] = base_features['len_ratio'].rolling(window).max()\n",
    "    \n",
    "    # base_features[f'len_ratio_{window}_mean_diff'] = base_features[f'len_ratio_{window}_mean'].diff(window)\n",
    "\n",
    "# base_features['mid_price_rolling_max_100'] = base_features.mid_price.diff(87).rolling(500).std()\n",
    "# base_features['mid_price_rolling_median_100'] = base_features.mid_price_log.rolling(87)\n",
    "# base_features['mid_price_rolling_max_100'] = base_features.mid_price_log.rolling(1000).max() - base_features.mid_price_log\n",
    "# base_features['mid_price_rolling_mean_10_diff'] = base_features.mid_price_log.rolling(400).mean().diff(10)\n",
    "# base_features['mid_price_rolling_std_100_diff'] = base_features.mid_price_log.rolling(100).max()\n",
    "# base_features['mid_price_rolling_std_10_diff'] = base_features.mid_price_log.rolling(400).std().diff(10)\n",
    "# time_folds.fit(base_features, data.y)\n",
    "\n",
    "# cross_val_runner = CrossValRunner(time_folds, **MODEL_CONFIGS['default_ridge'])\n",
    "# cross_val_runner.fit(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_folds = TimeFolds(n_folds=10, minifold_size=60000, neutral_ratio=0., test_ratio=0.2, test_neutral_ratio=0.1)\n",
    "time_folds.fit(base_features, data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9564ad77b6342c0a83035b3e70e5179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | dataset   | metric_name   |   fold_0 |   fold_1 |   fold_2 |   fold_3 |   fold_4 |   fold_5 |   fold_6 |   fold_7 |   fold_8 |   fold_9 |\n",
      "|---:|:----------|:--------------|---------:|---------:|---------:|---------:|---------:|---------:|---------:|---------:|---------:|---------:|\n",
      "|  0 | val       | mse           |    0.468 |    0.491 |    0.411 |    0.623 |    0.505 |    0.512 |    0.439 |    0.494 |    0.49  |    0.547 |\n",
      "|  1 | val       | corr          |    0.151 |    0.156 |    0.17  |    0.136 |    0.156 |    0.158 |    0.162 |    0.139 |    0.16  |    0.126 |\n",
      "|  2 | test      | mse           |    0.334 |    0.334 |    0.334 |    0.334 |    0.334 |    0.334 |    0.334 |    0.334 |    0.334 |    0.334 |\n",
      "|  3 | test      | corr          |    0.16  |    0.16  |    0.16  |    0.162 |    0.16  |    0.16  |    0.16  |    0.16  |    0.162 |    0.16  |\n",
      "        \t\tVal  corr averaged: 0.152\n",
      "        \t\tVal   MSE averaged: 0.498\n",
      "        \t\tTest corr averaged: 0.160\n",
      "        \t\tTest  MSE averaged: 0.334\n",
      "        ------------------------------------------------------------------\n",
      "        \t\tAveraged test  MSE: 0.334\n",
      "        \t\tAveraged test corr: 0.161\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "ridge_runner = CrossValRunner(time_folds, **MODEL_CONFIGS['default_ridge'])\n",
    "ridge_runner.fit(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53436cce5c704d3383d6d46b19daef29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.141794 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16781\n",
      "[LightGBM] [Info] Number of data points in the train set: 2374627, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score -0.000130\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's l2: 0.474747\n",
      "[100]\tvalid_0's l2: 0.472638\n",
      "[150]\tvalid_0's l2: 0.47144\n",
      "[200]\tvalid_0's l2: 0.470682\n",
      "[250]\tvalid_0's l2: 0.470159\n",
      "[300]\tvalid_0's l2: 0.46977\n",
      "[350]\tvalid_0's l2: 0.46949\n",
      "[400]\tvalid_0's l2: 0.469301\n",
      "[450]\tvalid_0's l2: 0.469161\n",
      "[500]\tvalid_0's l2: 0.469066\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.469066\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.147407 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16780\n",
      "[LightGBM] [Info] Number of data points in the train set: 2376674, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 0.000054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's l2: 0.498246\n",
      "[100]\tvalid_0's l2: 0.496069\n",
      "[150]\tvalid_0's l2: 0.494804\n",
      "[200]\tvalid_0's l2: 0.493973\n",
      "[250]\tvalid_0's l2: 0.49336\n",
      "[300]\tvalid_0's l2: 0.492897\n",
      "[350]\tvalid_0's l2: 0.492538\n",
      "[400]\tvalid_0's l2: 0.492284\n",
      "[450]\tvalid_0's l2: 0.49204\n",
      "[500]\tvalid_0's l2: 0.491848\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.491848\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.114890 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16782\n",
      "[LightGBM] [Info] Number of data points in the train set: 2376581, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 0.001555\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's l2: 0.418814\n",
      "[100]\tvalid_0's l2: 0.416826\n",
      "[150]\tvalid_0's l2: 0.415684\n",
      "[200]\tvalid_0's l2: 0.414894\n",
      "[250]\tvalid_0's l2: 0.414294\n",
      "[300]\tvalid_0's l2: 0.41379\n",
      "[350]\tvalid_0's l2: 0.413353\n",
      "[400]\tvalid_0's l2: 0.412965\n",
      "[450]\tvalid_0's l2: 0.412683\n",
      "[500]\tvalid_0's l2: 0.412441\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.412441\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.138933 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16756\n",
      "[LightGBM] [Info] Number of data points in the train set: 2377995, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 0.001030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's l2: 0.629604\n",
      "[100]\tvalid_0's l2: 0.627138\n",
      "[150]\tvalid_0's l2: 0.625796\n",
      "[200]\tvalid_0's l2: 0.625142\n",
      "[250]\tvalid_0's l2: 0.624814\n",
      "Early stopping, best iteration is:\n",
      "[240]\tvalid_0's l2: 0.624797\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.118100 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16779\n",
      "[LightGBM] [Info] Number of data points in the train set: 2378157, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 0.000626\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's l2: 0.513615\n",
      "[100]\tvalid_0's l2: 0.51135\n",
      "[150]\tvalid_0's l2: 0.509987\n",
      "[200]\tvalid_0's l2: 0.509105\n",
      "[250]\tvalid_0's l2: 0.508452\n",
      "[300]\tvalid_0's l2: 0.507911\n",
      "[350]\tvalid_0's l2: 0.507554\n",
      "[400]\tvalid_0's l2: 0.50725\n",
      "[450]\tvalid_0's l2: 0.506962\n",
      "[500]\tvalid_0's l2: 0.506686\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.506686\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.115898 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16770\n",
      "[LightGBM] [Info] Number of data points in the train set: 2378567, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score -0.002091\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's l2: 0.52001\n",
      "[100]\tvalid_0's l2: 0.517647\n",
      "[150]\tvalid_0's l2: 0.516395\n",
      "[200]\tvalid_0's l2: 0.515672\n",
      "[250]\tvalid_0's l2: 0.515107\n",
      "[300]\tvalid_0's l2: 0.514778\n",
      "[350]\tvalid_0's l2: 0.514527\n",
      "[400]\tvalid_0's l2: 0.514345\n",
      "[450]\tvalid_0's l2: 0.514247\n",
      "Early stopping, best iteration is:\n",
      "[481]\tvalid_0's l2: 0.514176\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.120447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16775\n",
      "[LightGBM] [Info] Number of data points in the train set: 2399381, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 0.000272\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's l2: 0.445584\n",
      "[100]\tvalid_0's l2: 0.443359\n",
      "[150]\tvalid_0's l2: 0.442115\n",
      "[200]\tvalid_0's l2: 0.441241\n",
      "[250]\tvalid_0's l2: 0.440661\n",
      "[300]\tvalid_0's l2: 0.440189\n",
      "[350]\tvalid_0's l2: 0.439821\n",
      "[400]\tvalid_0's l2: 0.43958\n",
      "[450]\tvalid_0's l2: 0.439337\n",
      "[500]\tvalid_0's l2: 0.439192\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[499]\tvalid_0's l2: 0.439189\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.117147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16775\n",
      "[LightGBM] [Info] Number of data points in the train set: 2433596, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 0.001118\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's l2: 0.499312\n",
      "[100]\tvalid_0's l2: 0.497448\n",
      "[150]\tvalid_0's l2: 0.496567\n",
      "[200]\tvalid_0's l2: 0.496191\n",
      "[250]\tvalid_0's l2: 0.495966\n",
      "Early stopping, best iteration is:\n",
      "[267]\tvalid_0's l2: 0.495889\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.116238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16760\n",
      "[LightGBM] [Info] Number of data points in the train set: 2432398, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 0.000798\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's l2: 0.498356\n",
      "[100]\tvalid_0's l2: 0.49602\n",
      "[150]\tvalid_0's l2: 0.494569\n",
      "[200]\tvalid_0's l2: 0.493643\n",
      "[250]\tvalid_0's l2: 0.492911\n",
      "[300]\tvalid_0's l2: 0.492442\n",
      "Early stopping, best iteration is:\n",
      "[334]\tvalid_0's l2: 0.49224\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.121686 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16765\n",
      "[LightGBM] [Info] Number of data points in the train set: 2434344, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 0.003746\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's l2: 0.551626\n",
      "[100]\tvalid_0's l2: 0.550253\n",
      "[150]\tvalid_0's l2: 0.549382\n",
      "[200]\tvalid_0's l2: 0.548935\n",
      "Early stopping, best iteration is:\n",
      "[233]\tvalid_0's l2: 0.548675\n",
      "|    | dataset   | metric_name   |   fold_0 |   fold_1 |   fold_2 |   fold_3 |   fold_4 |   fold_5 |   fold_6 |   fold_7 |   fold_8 |   fold_9 |\n",
      "|---:|:----------|:--------------|---------:|---------:|---------:|---------:|---------:|---------:|---------:|---------:|---------:|---------:|\n",
      "|  0 | val       | mse           |    0.469 |    0.492 |    0.412 |    0.625 |    0.507 |    0.514 |    0.439 |    0.496 |    0.492 |    0.549 |\n",
      "|  1 | val       | corr          |    0.147 |    0.151 |    0.162 |    0.125 |    0.151 |    0.145 |    0.16  |    0.125 |    0.153 |    0.113 |\n",
      "|  2 | test      | mse           |    0.338 |    0.337 |    0.338 |    0.335 |    0.338 |    0.337 |    0.337 |    0.335 |    0.335 |    0.335 |\n",
      "|  3 | test      | corr          |    0.141 |    0.146 |    0.145 |    0.146 |    0.14  |    0.145 |    0.143 |    0.145 |    0.147 |    0.146 |\n",
      "        \t\tVal  corr averaged: 0.143\n",
      "        \t\tVal   MSE averaged: 0.500\n",
      "        \t\tTest corr averaged: 0.144\n",
      "        \t\tTest  MSE averaged: 0.336\n",
      "        ------------------------------------------------------------------\n",
      "        \t\tAveraged test  MSE: 0.336\n",
      "        \t\tAveraged test corr: 0.149\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "lgbm_runner = CrossValRunner(time_folds, **MODEL_CONFIGS['default_lgbm'])\n",
    "lgbm_runner.fit(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd7e9ef49e04bee9a7da85598bcd28a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.114383 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16781\n",
      "[LightGBM] [Info] Number of data points in the train set: 2374627, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score -0.000130\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's l2: 0.473226\n",
      "[100]\tvalid_0's l2: 0.470574\n",
      "[150]\tvalid_0's l2: 0.469298\n",
      "[200]\tvalid_0's l2: 0.468512\n",
      "[250]\tvalid_0's l2: 0.468087\n",
      "Early stopping, best iteration is:\n",
      "[271]\tvalid_0's l2: 0.467952\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.111069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16780\n",
      "[LightGBM] [Info] Number of data points in the train set: 2376674, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 0.000054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's l2: 0.496603\n",
      "[100]\tvalid_0's l2: 0.493799\n",
      "[150]\tvalid_0's l2: 0.492533\n",
      "[200]\tvalid_0's l2: 0.491789\n",
      "[250]\tvalid_0's l2: 0.491364\n",
      "[300]\tvalid_0's l2: 0.491146\n",
      "Early stopping, best iteration is:\n",
      "[297]\tvalid_0's l2: 0.491112\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.113218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16782\n",
      "[LightGBM] [Info] Number of data points in the train set: 2376581, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 0.001555\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's l2: 0.417227\n",
      "[100]\tvalid_0's l2: 0.414585\n",
      "[150]\tvalid_0's l2: 0.413067\n",
      "[200]\tvalid_0's l2: 0.412213\n",
      "[250]\tvalid_0's l2: 0.41162\n",
      "[300]\tvalid_0's l2: 0.411335\n",
      "[350]\tvalid_0's l2: 0.411111\n",
      "Early stopping, best iteration is:\n",
      "[356]\tvalid_0's l2: 0.411094\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.114133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16756\n",
      "[LightGBM] [Info] Number of data points in the train set: 2377995, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 0.001030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's l2: 0.627981\n",
      "[100]\tvalid_0's l2: 0.625932\n",
      "Early stopping, best iteration is:\n",
      "[116]\tvalid_0's l2: 0.625711\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.112978 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16779\n",
      "[LightGBM] [Info] Number of data points in the train set: 2378157, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 0.000626\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's l2: 0.511806\n",
      "[100]\tvalid_0's l2: 0.508919\n",
      "[150]\tvalid_0's l2: 0.507481\n",
      "[200]\tvalid_0's l2: 0.506566\n",
      "[250]\tvalid_0's l2: 0.506051\n",
      "[300]\tvalid_0's l2: 0.505641\n",
      "[350]\tvalid_0's l2: 0.505372\n",
      "Early stopping, best iteration is:\n",
      "[350]\tvalid_0's l2: 0.505372\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.122289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16770\n",
      "[LightGBM] [Info] Number of data points in the train set: 2378567, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score -0.002091\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's l2: 0.518276\n",
      "[100]\tvalid_0's l2: 0.515758\n",
      "[150]\tvalid_0's l2: 0.515013\n",
      "[200]\tvalid_0's l2: 0.514659\n",
      "Early stopping, best iteration is:\n",
      "[211]\tvalid_0's l2: 0.514596\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.115296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16775\n",
      "[LightGBM] [Info] Number of data points in the train set: 2399381, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 0.000272\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's l2: 0.444301\n",
      "[100]\tvalid_0's l2: 0.4416\n",
      "[150]\tvalid_0's l2: 0.440525\n",
      "[200]\tvalid_0's l2: 0.440031\n",
      "Early stopping, best iteration is:\n",
      "[209]\tvalid_0's l2: 0.439957\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.123508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16775\n",
      "[LightGBM] [Info] Number of data points in the train set: 2433596, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 0.001118\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's l2: 0.49864\n",
      "[100]\tvalid_0's l2: 0.496867\n",
      "Early stopping, best iteration is:\n",
      "[129]\tvalid_0's l2: 0.496543\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.143057 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16760\n",
      "[LightGBM] [Info] Number of data points in the train set: 2432398, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 0.000798\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's l2: 0.496304\n",
      "[100]\tvalid_0's l2: 0.492744\n",
      "[150]\tvalid_0's l2: 0.491515\n",
      "[200]\tvalid_0's l2: 0.491042\n",
      "Early stopping, best iteration is:\n",
      "[216]\tvalid_0's l2: 0.490939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.147224 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16765\n",
      "[LightGBM] [Info] Number of data points in the train set: 2434344, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 0.003746\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's l2: 0.550311\n",
      "[100]\tvalid_0's l2: 0.549038\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's l2: 0.548705\n",
      "|    | dataset   | metric_name   |   fold_0 |   fold_1 |   fold_2 |   fold_3 |   fold_4 |   fold_5 |   fold_6 |   fold_7 |   fold_8 |   fold_9 |\n",
      "|---:|:----------|:--------------|---------:|---------:|---------:|---------:|---------:|---------:|---------:|---------:|---------:|---------:|\n",
      "|  0 | val       | mse           |    0.468 |    0.491 |    0.411 |    0.626 |    0.505 |    0.515 |    0.44  |    0.497 |    0.491 |    0.549 |\n",
      "|  1 | val       | corr          |    0.154 |    0.153 |    0.17  |    0.118 |    0.158 |    0.141 |    0.154 |    0.12  |    0.157 |    0.114 |\n",
      "|  2 | test      | mse           |    0.345 |    0.35  |    0.353 |    0.338 |    0.355 |    0.346 |    0.343 |    0.339 |    0.345 |    0.339 |\n",
      "|  3 | test      | corr          |    0.105 |    0.096 |    0.094 |    0.131 |    0.09  |    0.091 |    0.101 |    0.108 |    0.094 |    0.104 |\n",
      "        \t\tVal  corr averaged: 0.144\n",
      "        \t\tVal   MSE averaged: 0.499\n",
      "        \t\tTest corr averaged: 0.101\n",
      "        \t\tTest  MSE averaged: 0.345\n",
      "        ------------------------------------------------------------------\n",
      "        \t\tAveraged test  MSE: 0.343\n",
      "        \t\tAveraged test corr: 0.108\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "current_lgbm = {\n",
    "    'model_module': 'lightgbm',\n",
    "    'model_cls': 'LGBMRegressor',\n",
    "    'model_params': {\n",
    "        'n_jobs': -1, \n",
    "        'num_leaves': 255, \n",
    "        'learning_rate': 0.01,\n",
    "        'n_estimators': 2000, \n",
    "        'reg_lambda': 1, \n",
    "        'reg_alpha': 1,\n",
    "        'colsample_bytree': 0.7, \n",
    "        'subsample': 0.05\n",
    "    }\n",
    "}\n",
    "time_folds = TimeFolds(n_folds=10, minifold_size=60000, neutral_ratio=0., test_ratio=0.2, test_neutral_ratio=0.1)\n",
    "time_folds.fit(base_features, data.y)\n",
    "lgbm_runner = CrossValRunner(time_folds, **current_lgbm)\n",
    "lgbm_runner.fit(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f49f80eeff024629b64deeabebeaea22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.110028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16781\n",
      "[LightGBM] [Info] Number of data points in the train set: 2374627, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score -0.000130\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's l2: 0.473226\n",
      "[100]\tvalid_0's l2: 0.470574\n",
      "[150]\tvalid_0's l2: 0.469298\n",
      "[200]\tvalid_0's l2: 0.468512\n",
      "[250]\tvalid_0's l2: 0.468087\n",
      "Early stopping, best iteration is:\n",
      "[271]\tvalid_0's l2: 0.467952\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.122416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16780\n",
      "[LightGBM] [Info] Number of data points in the train set: 2376674, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 0.000054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's l2: 0.496603\n",
      "[100]\tvalid_0's l2: 0.493799\n",
      "[150]\tvalid_0's l2: 0.492533\n",
      "[200]\tvalid_0's l2: 0.491789\n",
      "[250]\tvalid_0's l2: 0.491364\n",
      "[300]\tvalid_0's l2: 0.491146\n",
      "Early stopping, best iteration is:\n",
      "[297]\tvalid_0's l2: 0.491112\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.128221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16782\n",
      "[LightGBM] [Info] Number of data points in the train set: 2376581, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 0.001555\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's l2: 0.417227\n",
      "[100]\tvalid_0's l2: 0.414585\n",
      "[150]\tvalid_0's l2: 0.413067\n",
      "[200]\tvalid_0's l2: 0.412213\n",
      "[250]\tvalid_0's l2: 0.41162\n",
      "[300]\tvalid_0's l2: 0.411335\n",
      "[350]\tvalid_0's l2: 0.411111\n",
      "Early stopping, best iteration is:\n",
      "[356]\tvalid_0's l2: 0.411094\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.125396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16756\n",
      "[LightGBM] [Info] Number of data points in the train set: 2377995, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 0.001030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's l2: 0.627981\n",
      "[100]\tvalid_0's l2: 0.625932\n",
      "Early stopping, best iteration is:\n",
      "[116]\tvalid_0's l2: 0.625711\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.124007 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16779\n",
      "[LightGBM] [Info] Number of data points in the train set: 2378157, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 0.000626\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's l2: 0.511806\n",
      "[100]\tvalid_0's l2: 0.508919\n",
      "[150]\tvalid_0's l2: 0.507481\n",
      "[200]\tvalid_0's l2: 0.506566\n",
      "[250]\tvalid_0's l2: 0.506051\n",
      "[300]\tvalid_0's l2: 0.505641\n",
      "[350]\tvalid_0's l2: 0.505372\n",
      "Early stopping, best iteration is:\n",
      "[350]\tvalid_0's l2: 0.505372\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.110892 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16770\n",
      "[LightGBM] [Info] Number of data points in the train set: 2378567, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score -0.002091\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's l2: 0.518276\n",
      "[100]\tvalid_0's l2: 0.515758\n",
      "[150]\tvalid_0's l2: 0.515013\n",
      "[200]\tvalid_0's l2: 0.514659\n",
      "Early stopping, best iteration is:\n",
      "[211]\tvalid_0's l2: 0.514596\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.121901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16775\n",
      "[LightGBM] [Info] Number of data points in the train set: 2399381, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 0.000272\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's l2: 0.444301\n",
      "[100]\tvalid_0's l2: 0.4416\n",
      "[150]\tvalid_0's l2: 0.440525\n",
      "[200]\tvalid_0's l2: 0.440031\n",
      "Early stopping, best iteration is:\n",
      "[209]\tvalid_0's l2: 0.439957\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.132002 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16775\n",
      "[LightGBM] [Info] Number of data points in the train set: 2433596, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 0.001118\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's l2: 0.49864\n",
      "[100]\tvalid_0's l2: 0.496867\n",
      "Early stopping, best iteration is:\n",
      "[129]\tvalid_0's l2: 0.496543\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.118526 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16760\n",
      "[LightGBM] [Info] Number of data points in the train set: 2432398, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 0.000798\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's l2: 0.496304\n",
      "[100]\tvalid_0's l2: 0.492744\n",
      "[150]\tvalid_0's l2: 0.491515\n",
      "[200]\tvalid_0's l2: 0.491042\n",
      "Early stopping, best iteration is:\n",
      "[216]\tvalid_0's l2: 0.490939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.114805 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16765\n",
      "[LightGBM] [Info] Number of data points in the train set: 2434344, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 0.003746\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's l2: 0.550311\n",
      "[100]\tvalid_0's l2: 0.549038\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's l2: 0.548705\n",
      "|    | dataset   | metric_name   |   fold_0 |   fold_1 |   fold_2 |   fold_3 |   fold_4 |   fold_5 |   fold_6 |   fold_7 |   fold_8 |   fold_9 |\n",
      "|---:|:----------|:--------------|---------:|---------:|---------:|---------:|---------:|---------:|---------:|---------:|---------:|---------:|\n",
      "|  0 | val       | mse           |    0.468 |    0.491 |    0.411 |    0.626 |    0.505 |    0.515 |    0.44  |    0.497 |    0.491 |    0.549 |\n",
      "|  1 | val       | corr          |    0.154 |    0.153 |    0.17  |    0.118 |    0.158 |    0.141 |    0.154 |    0.12  |    0.157 |    0.114 |\n",
      "|  2 | test      | mse           |    0.345 |    0.35  |    0.353 |    0.338 |    0.355 |    0.346 |    0.343 |    0.339 |    0.345 |    0.339 |\n",
      "|  3 | test      | corr          |    0.105 |    0.096 |    0.094 |    0.131 |    0.09  |    0.091 |    0.101 |    0.108 |    0.094 |    0.104 |\n",
      "        \t\tVal  corr averaged: 0.144\n",
      "        \t\tVal   MSE averaged: 0.499\n",
      "        \t\tTest corr averaged: 0.101\n",
      "        \t\tTest  MSE averaged: 0.345\n",
      "        ------------------------------------------------------------------\n",
      "        \t\tAveraged test  MSE: 0.343\n",
      "        \t\tAveraged test corr: 0.108\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "current_lgbm_v2 = {\n",
    "    'model_module': 'lightgbm',\n",
    "    'model_cls': 'LGBMRegressor',\n",
    "    'model_params': {\n",
    "        'n_jobs': -1, \n",
    "        'num_leaves': 255, \n",
    "        'learning_rate': 0.01,\n",
    "        'n_estimators': 2000, \n",
    "        'reg_lambda': 1, \n",
    "        'reg_alpha': 1,\n",
    "        'colsample_bytree': 0.7, \n",
    "        'subsample': 0.3\n",
    "    }\n",
    "}\n",
    "\n",
    "lgbm_runner_v2 = CrossValRunner(time_folds, **current_lgbm_v2)\n",
    "lgbm_runner_v2.fit(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.33092325076038726, 0.16676269522399212)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "predicted = (ridge_runner.averaged_test * 0.6 + cross_val_runner.averaged_test * 0.3 + lasso_runner.averaged_test * 0.1)\n",
    "corr_score = np.corrcoef(predicted, ridge_runner.report.test_target)[0,1]\n",
    "mse_score = mean_squared_error(predicted, ridge_runner.report.test_target)\n",
    "mse_score, corr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_runner = CrossValRunner(time_folds, **MODEL_CONFIGS['default_lasso'])\n",
    "lasso_runner.fit(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3319893397593852, 0.16341332428995836)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_meta = np.vstack((cross_val_runner.oof, ridge_runner.oof, lasso_runner.oof)).T[:time_folds.train_size]\n",
    "nan_idxs = np.isnan(train_meta).any(1)\n",
    "meta_model = Ridge(alpha=1)\n",
    "train_meta_target = time_folds.target[:time_folds.train_size]\n",
    "train_meta_target = train_meta_target[~nan_idxs]\n",
    "\n",
    "meta_model.fit(train_meta[~nan_idxs], train_meta_target)\n",
    "\n",
    "test_meta = np.vstack((ridge_runner.averaged_test, cross_val_runner.averaged_test, lasso_runner.averaged_test)).T\n",
    "test_target = ridge_runner.report.test_target\n",
    "predicted_test = meta_model.predict(test_meta)\n",
    "\n",
    "corr_score = np.corrcoef(predicted_test, test_target)[0,1]\n",
    "mse_score = mean_squared_error(predicted_test, test_target)\n",
    "mse_score, corr_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ..., False, False, False])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.13624127],\n",
       "       [0.13624127, 1.        ]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_x = cross_val_runner.oof[:time_folds.train_size]\n",
    "nan_idxs = np.isnan(oof_x)\n",
    "oof_x = oof_x[~nan_idxs]\n",
    "\n",
    "oof_target = time_folds.target[:time_folds.train_size]\n",
    "oof_target = oof_target[~nan_idxs]\n",
    "np.corrcoef(oof_x, oof_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nan_idxs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/sneddy/projects/xtx/notebooks/reasonable_features.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sneddy/projects/xtx/notebooks/reasonable_features.ipynb#ch0000073?line=0'>1</a>\u001b[0m oof_x[\u001b[39m~\u001b[39mnan_idxs]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nan_idxs' is not defined"
     ]
    }
   ],
   "source": [
    "oof_x[~nan_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_features['progressive_ask_count'] = np.dot(data[ask_size_cols].values, np.arange(1, 16)[::-1]) / 15\n",
    "# base_features['progressive_bid_count'] = np.dot(data[bid_size_cols].values, np.arange(1, 16)[::-1]) / 15\n",
    "# base_features[['progressive_ask_count', 'progressive_bid_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_features['ask_rate0_changed'] = data.askRate0.diff() \n",
    "# base_features['bid_rate0_changed'] = data.bidRate0.diff() \n",
    "\n",
    "# base_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_features = make_base_features(data)\n",
    "base_columns = base_features.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          1615.0\n",
       "1          1615.0\n",
       "2          1615.0\n",
       "3          1615.0\n",
       "4          1615.0\n",
       "            ...  \n",
       "3497661    1575.0\n",
       "3497662    1575.0\n",
       "3497663    1575.0\n",
       "3497664    1575.0\n",
       "3497665    1575.0\n",
       "Name: bid_flatten_mean_5, Length: 3497666, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_features[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init correlation: 0.1428\n",
      "Init MSE: 0.6428\n",
      "Init test correlation: 0.1502\n",
      "Init test MSE: 0.3312\n",
      "ask_flatten_mean_5 0.3321552019960154\n",
      "ask_flatten_std_5 0.33209220243242804\n",
      "ask_flatten_skew_5 0.332031915654447\n",
      "==================================================\n",
      "ask_flatten_kurtosis_5 0.6428091322447211\n",
      "==================================================\n",
      "bid_flatten_mean_5 0.6427935603490048\n",
      "bid_flatten_skew_5 0.3320685692075931\n",
      "bid_flatten_kurtosis_5 0.3320037473032549\n",
      "flatten_spread_5_mean 0.33210796339473503\n",
      "==================================================\n",
      "wap_flatten_5 0.6427678402254664\n",
      "==================================================\n",
      "bid_flatten_std_5 0.6423377632419085\n",
      "ask_flatten_mean_10 0.33212082073242516\n",
      "ask_flatten_median_10 0.3320779180775223\n",
      "ask_flatten_std_10 0.3320004297867703\n",
      "ask_flatten_iqr_10 0.3318913539396287\n",
      "ask_flatten_skew_10 0.3319032966209914\n",
      "==================================================\n",
      "ask_flatten_kurtosis_10 0.6422866813282984\n",
      "bid_flatten_mean_10 0.33192402578218994\n",
      "bid_flatten_median_10 0.3318660697421667\n",
      "==================================================\n",
      "bid_flatten_iqr_10 0.6421884359271357\n",
      "==================================================\n",
      "bid_flatten_skew_10 0.6421483776155109\n",
      "==================================================\n",
      "bid_flatten_kurtosis_10 0.6420894123513163\n",
      "flatten_spread_10_mean 0.331882226990282\n",
      "flatten_spread_10_median 0.33183001801009987\n",
      "==================================================\n",
      "wap_flatten_10 0.6419616308257237\n",
      "==================================================\n",
      "bid_flatten_std_10 0.6417580379409142\n",
      "ask_flatten_mean_15 0.33220160793703873\n",
      "ask_flatten_median_15 0.33217875927027807\n",
      "ask_flatten_std_15 0.33199963591502124\n",
      "ask_flatten_iqr_15 0.3320890704517874\n",
      "==================================================\n",
      "ask_flatten_skew_15 0.6417579879337282\n",
      "ask_flatten_kurtosis_15 0.33203546000285167\n",
      "bid_flatten_mean_15 0.33198663282005064\n",
      "bid_flatten_median_15 0.3319218970031073\n",
      "bid_flatten_iqr_15 0.3319168546035191\n",
      "bid_flatten_skew_15 0.3319519896313298\n",
      "==================================================\n",
      "bid_flatten_kurtosis_15 0.6417438903467038\n",
      "flatten_spread_15_mean 0.3319195821590736\n",
      "flatten_spread_15_median 0.3318124481140031\n",
      "==================================================\n",
      "wap_flatten_15 0.6415604899917124\n",
      "bid_flatten_std_15 0.33199226263922976\n",
      "ask_flatten_mean_50 0.33237194540097476\n",
      "==================================================\n",
      "ask_flatten_median_50 0.6414168806645135\n",
      "ask_flatten_std_50 0.33235044472094305\n",
      "ask_flatten_iqr_50 0.3323577594708454\n",
      "==================================================\n",
      "ask_flatten_skew_50 0.6413592529142235\n",
      "ask_flatten_kurtosis_50 0.3323742654354267\n",
      "==================================================\n",
      "bid_flatten_mean_50 0.6411256635630461\n",
      "bid_flatten_median_50 0.332154430993046\n",
      "bid_flatten_iqr_50 0.33214595455023466\n",
      "bid_flatten_skew_50 0.3321967999377253\n",
      "==================================================\n",
      "bid_flatten_kurtosis_50 0.641081417191843\n",
      "flatten_spread_50_mean 0.33218092961436285\n",
      "flatten_spread_50_median 0.33217349820472664\n",
      "wap_flatten_50 0.3321753272172906\n",
      "ask_flatten_len_100 0.33216687267017136\n",
      "==================================================\n",
      "ask_flatten_mean_100 0.6403390271714243\n",
      "ask_flatten_median_100 0.332209443855885\n",
      "==================================================\n",
      "ask_flatten_std_100 0.6403148554505851\n",
      "==================================================\n",
      "ask_flatten_iqr_100 0.640251525185396\n",
      "==================================================\n",
      "ask_flatten_skew_100 0.6401591398645947\n",
      "ask_flatten_kurtosis_100 0.33225620537684847\n",
      "==================================================\n",
      "bid_flatten_len_100 0.6398696688338148\n",
      "bid_flatten_mean_100 0.33240538835052597\n",
      "bid_flatten_median_100 0.3322729798022256\n",
      "bid_flatten_iqr_100 0.3324903554826431\n",
      "==================================================\n",
      "bid_flatten_skew_100 0.6398629689474947\n",
      "bid_flatten_kurtosis_100 0.33219870024847764\n",
      "flatten_spread_100_mean 0.3323320859208906\n",
      "flatten_spread_100_median 0.3322297503666603\n",
      "wap_flatten_100 0.3323984996830306\n",
      "bid_flatten_std_100 0.3324172487347464\n"
     ]
    }
   ],
   "source": [
    "time_folds = TimeFolds(n_folds=5, minifold_size=60000, neutral_ratio=0.1, test_ratio=0.2)\n",
    "usecols = base_columns\n",
    "\n",
    "time_folds.fit(base_features, data.y)\n",
    "best_score, _ = ridge_eval(time_folds, 3, 100)\n",
    "for col in topk_features.columns:\n",
    "    base_features[col] = topk_features[col]\n",
    "    usecols.append(col)\n",
    "    \n",
    "    time_folds = TimeFolds(n_folds=5, minifold_size=60000, neutral_ratio=0.1, test_ratio=0.2)\n",
    "    time_folds.fit(base_features.loc[:, usecols], data.y)\n",
    "    mse_score, test_mse_score = ridge_eval(time_folds, 3, 100, verbose=False)\n",
    "    if mse_score < best_score:\n",
    "        best_score = mse_score\n",
    "        print('=' * 50)\n",
    "        print(col, best_score)\n",
    "    else:\n",
    "        usecols = usecols[:-1]\n",
    "        print(col, mse_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ask_rate_0',\n",
       " 'mid_price',\n",
       " 'mid_price_log',\n",
       " 'ask_len',\n",
       " 'bid_len',\n",
       " 'wap0',\n",
       " 'wap1',\n",
       " 'len_ratio',\n",
       " 'volume_imbalance',\n",
       " 'increased_ask_counts',\n",
       " 'decreased_ask_counts',\n",
       " 'increased_bid_counts',\n",
       " 'decreased_bid_counts',\n",
       " 'ask_flatten_len_5',\n",
       " 'ask_flatten_len_5',\n",
       " 'ask_flatten_len_5',\n",
       " 'ask_flatten_kurtosis_5',\n",
       " 'bid_flatten_mean_5',\n",
       " 'wap_flatten_5',\n",
       " 'bid_flatten_std_5',\n",
       " 'ask_flatten_kurtosis_10',\n",
       " 'bid_flatten_iqr_10',\n",
       " 'bid_flatten_skew_10',\n",
       " 'bid_flatten_kurtosis_10',\n",
       " 'wap_flatten_10',\n",
       " 'bid_flatten_std_10',\n",
       " 'ask_flatten_skew_15',\n",
       " 'bid_flatten_kurtosis_15',\n",
       " 'wap_flatten_15',\n",
       " 'ask_flatten_median_50',\n",
       " 'ask_flatten_skew_50',\n",
       " 'bid_flatten_mean_50',\n",
       " 'bid_flatten_kurtosis_50',\n",
       " 'ask_flatten_mean_100',\n",
       " 'ask_flatten_std_100',\n",
       " 'ask_flatten_iqr_100',\n",
       " 'ask_flatten_skew_100',\n",
       " 'bid_flatten_len_100',\n",
       " 'bid_flatten_skew_100']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usecols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init correlation: 0.1404\n",
      "Init MSE: 0.6430\n",
      "Init test correlation: 0.1520\n",
      "Init test MSE: 0.3322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6430450248193251, 0.3321552019960154)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xtx.time_folds import TimeFolds\n",
    "\n",
    "\n",
    "time_folds = TimeFolds(n_folds=5, minifold_size=60000, neutral_ratio=0.1, test_ratio=0.2)\n",
    "time_folds.fit(base_features[base_columns], data.y)\n",
    "ridge_eval(time_folds, 3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init correlation: 0.1527\n",
      "Init MSE: 0.6407\n",
      "Init test correlation: 0.1537\n",
      "Init test MSE: 0.3325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6407272279996943, 0.3324579275214507)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xtx.time_folds import TimeFolds\n",
    "\n",
    "\n",
    "time_folds = TimeFolds(n_folds=5, minifold_size=60000, neutral_ratio=0.1, test_ratio=0.2)\n",
    "time_folds.fit(base_features[usecols], data.y)\n",
    "ridge_eval(time_folds, 3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ask_rate_0',\n",
       " 'mid_price',\n",
       " 'mid_price_log',\n",
       " 'ask_len',\n",
       " 'bid_len',\n",
       " 'wap0',\n",
       " 'wap1',\n",
       " 'len_ratio',\n",
       " 'volume_imbalance',\n",
       " 'increased_ask_counts',\n",
       " 'decreased_ask_counts',\n",
       " 'increased_bid_counts',\n",
       " 'decreased_bid_counts',\n",
       " 'bid_flatten_mean_5',\n",
       " 'wap_flatten_10',\n",
       " 'ask_flatten_skew_15',\n",
       " 'bid_flatten_kurtosis_15',\n",
       " 'wap_flatten_15',\n",
       " 'ask_flatten_skew_50',\n",
       " 'bid_flatten_mean_50',\n",
       " 'bid_flatten_kurtosis_50',\n",
       " 'ask_flatten_mean_100',\n",
       " 'ask_flatten_iqr_100',\n",
       " 'bid_flatten_skew_100']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_features = pd.concat((base_features.reset_index(drop=True), topk_features.reset_index(drop=True)), axis=1)\n",
    "# merged_features.shape\n",
    "# merged_features.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xtx.time_folds import TimeFolds\n",
    "\n",
    "\n",
    "time_folds = TimeFolds(n_folds=5, minifold_size=60000, neutral_ratio=0.1, test_ratio=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init correlation: 0.1381\n",
      "Init MSE: 0.6434\n",
      "Init test correlation: 0.1515\n",
      "Init test MSE: 0.3319\n"
     ]
    }
   ],
   "source": [
    "time_folds.fit(base_features, data.y)\n",
    "ridge_eval(time_folds, 3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init correlation: 0.1356\n",
      "Init MSE: 0.6437\n",
      "Init test correlation: 0.1419\n",
      "Init test MSE: 0.3314\n"
     ]
    }
   ],
   "source": [
    "time_folds.fit(topk_features, data.y)\n",
    "ridge_eval(time_folds, 3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_features['ask_size_top3cols_ratio'] = data[ask_size_cols[:3]].sum(1) / base_features['ask_len']\n",
    "# base_features['bid_size_top3cols_ratio'] = data[bid_size_cols[:3]].sum(1) / base_features['bid_len']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2258133, 26) (431991, 26) (699533, 26)\n"
     ]
    }
   ],
   "source": [
    "from xtx.time_folds import TimeFolds\n",
    "\n",
    "time_folds = TimeFolds(n_folds=5, minifold_size=60000, neutral_ratio=0.1, test_ratio=0.2)\n",
    "time_folds.fit(base_features, data.y)\n",
    "\n",
    "fold_id = 3\n",
    "train_data = time_folds.get_train_data(fold_id)\n",
    "train_target = time_folds.get_train_target(fold_id)\n",
    "valid_data = time_folds.get_valid_data(fold_id)\n",
    "valid_target = time_folds.get_valid_target(fold_id)\n",
    "test_data = time_folds.get_test_data()\n",
    "test_target = time_folds.get_test_target()\n",
    "\n",
    "print(train_data.shape, valid_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dropna(inplace=True)\n",
    "valid_data.dropna(inplace=True)\n",
    "test_data.dropna(inplace=True)\n",
    "\n",
    "train_target = train_target.loc[train_data.index]\n",
    "valid_target = valid_target.loc[valid_data.index]\n",
    "test_target = test_target.loc[test_data.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "scaler = RobustScaler().fit(train_data)\n",
    "train_data_norm = scaler.transform(train_data)\n",
    "valid_data_norm = scaler.transform(valid_data)\n",
    "test_data_norm = scaler.transform(test_data.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init correlation: 0.141755\n",
      "Init MSE: 0.642837\n",
      "Init test correlation: 0.151614\n",
      "Init test MSE: 0.332012\n"
     ]
    }
   ],
   "source": [
    "model = Ridge(alpha=100)\n",
    "\n",
    "model.fit(train_data_norm, train_target)\n",
    "predicted = model.predict(valid_data_norm)\n",
    "corr_score = np.corrcoef(predicted, valid_target)[0,1]\n",
    "mse_score = mean_squared_error(predicted, valid_target)\n",
    "\n",
    "test_predicted = model.predict(test_data_norm)\n",
    "test_corr_score = np.corrcoef(test_predicted, test_target)[0,1]\n",
    "test_mse_score = mean_squared_error(test_predicted, test_target)\n",
    "print(f'Init correlation: {corr_score:.6f}')\n",
    "print(f'Init MSE: {mse_score:.6f}')\n",
    "print(f'Init test correlation: {test_corr_score:.6f}')\n",
    "print(f'Init test MSE: {test_mse_score:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
