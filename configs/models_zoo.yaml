selection_ridge:
    model_module: sklearn.linear_model
    model_cls: Ridge
    model_params:
        alpha: 10

stacking_zoo:
    stacking_ridge:
        model_module: sklearn.linear_model
        model_cls: Ridge
        model_params:
          alpha: 1
          positive: True

    stacking_lasso:
        model_module: sklearn.linear_model
        model_cls: Lasso
        model_params:
          alpha: 0.01
          positive: True

    stacking_elastic:
        model_module: sklearn.linear_model
        model_cls: ElasticNet
        model_params:
            alpha: 0.1
            l1_ratio: 0.1
            positive: True
    stacking_lgbm:
        model_module: lightgbm
        model_cls: LGBMRegressor
        model_params:
            n_jobs: -1
            boosting_type: dart
            colsample_bytree: 0.45
            drop_rate: 0.6
            learning_rate: 0.1
            max_depth: 4
            min_child_samples: 50000
            min_child_weight: 0.035
            n_estimators: 100
            objective: regression
            skip_drop: 0.8
            subsample: 0.8
            verbose: -1
train_zoo:
    default_ridge:
        model_module: sklearn.linear_model
        model_cls: Ridge
        model_params:
          alpha: 100
    bayesian_ridge:
        model_module: sklearn.linear_model
        model_cls: BayesianRidge
        model_params:
    default_lasso:
        model_module: sklearn.linear_model
        model_cls: Lasso
        model_params:
          alpha: 0.01
    one_epoch_mlp:
        model_module: sklearn.neural_network
        model_cls: MLPRegressor
        model_params:
          alpha: 1.
          hidden_layer_sizes: [40, ]
          learning_rate_init: 0.01
          learning_rate: adaptive
          solver: sgd
          tol: 0.0001
          max_iter: 1
          verbose: True
    well_reg_mlp:
        model_module: sklearn.neural_network
        model_cls: MLPRegressor
        model_params:
          alpha: 100.
          hidden_layer_sizes: [10]
          learning_rate_init: 0.01
          learning_rate: adaptive
          solver: adam
          batch_size: 30000
          tol: 0.0001
          max_iter: 15
          verbose: True

    default_dart:
        model_module: lightgbm
        model_cls: LGBMRegressor
        model_params:
            n_jobs: -1
            boosting_type: dart
            colsample_bytree: 0.45
            drop_rate: 0.6
            learning_rate: 0.02
            max_depth: 4
            min_child_samples: 20000
            min_child_weight: 0.035
            n_estimators: 1000
            objective: regression
            skip_drop: 0.8
            subsample: 0.8
            verbose: -1
    fast_dart:
        model_module: lightgbm
        model_cls: LGBMRegressor
        model_params:
            n_jobs: -1
            boosting_type: dart
            colsample_bytree: 0.45
            drop_rate: 0.6
            learning_rate: 0.05
            max_depth: 4
            min_child_samples: 20000
            min_child_weight: 0.035
            n_estimators: 400
            objective: regression
            skip_drop: 0.8
            subsample: 0.8
            verbose: -1
    default_logreg:
        model_module: sklearn.linear_model
        model_cls: LogisticRegression
        model_params:
            C: 1
            n_jobs: -1
            solver: saga
            tol: 0.01
            # penalty: elasticnet
    default_lgbm:
        model_module: lightgbm
        model_cls: LGBMRegressor
        model_params:
            n_jobs: -1
            num_leaves: 11
            max_depth: 5
            learning_rate: 0.02
            n_estimators: 1000
            reg_lambda: 3.5
            colsample_bytree: 0.2
            subsample: 0.15
            min_child_samples: 10000
            force_col_wise: True
            verbose: -1
    # another_lgbm:
    #     model_module: lightgbm
    #     model_cls: LGBMRegressor
    #     model_params:
    #         n_jobs: -1
    #         num_leaves: 13
    #         max_depth: 5
    #         learning_rate: 0.01
    #         n_estimators: 1000
    #         reg_lambda: 3.5
    #         colsample_bytree: 0.7
    #         subsample: 0.15
    #         min_child_samples: 10000
    #         force_col_wise: True
    wild_lgbm:
        model_module: lightgbm
        model_cls: LGBMRegressor
        model_params:
            n_jobs: -1
            num_leaves: 255
            learning_rate: 0.01
            n_estimators: 600
            reg_lambda: 10
            reg_alpha: 2
            colsample_bytree: 0.5
            min_child_samples: 1000
            subsample: 0.05
            force_col_wise: True
            verbose: -1
